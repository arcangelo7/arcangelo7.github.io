---
{"publish":true,"created":"2025-10-15T16:14:46.513+02:00","modified":"2023-06-06T12:00:00.000+02:00","cssclasses":""}
---


## Novità

**Meta**

- Ho aggiunto un nuovo parametro al software che genera il dump in CSV, ovvero una lista di schemi di identificatori da considerare nella generazione del dump. È servito per velocizzare la generazione del dump in CSV di POCI.

**Articolo JWS**

- Ho aggiunto ColChain ai related works
- Ho scritto lo pseudocodice degli algoritmi di query sulle versioni e sui delta
- Registro il tempo per ingerire ogni versione. C’è un cache che permette di ripartire dall’ultima versione non processata.
- La provenance viene salvata su un db a parte per misurare l’impatto sul disco
- Risolto un bug in rdflib_ocdm per cui commit_changes generava lo snapshot di creazione per le entità assenti nel contatore della provenance anziché limitarsi a resettare il preexisting graph
- Risolto un altro bug per cui la funzione per incrementare il contatore su sqllite encodava l'url che funge da chiave due volte

[[attachments/fe9a4b44eb264ceea1d19104a5ec91de]]

## Domande

- Strategie per velocizzare l’ingestione di dbpedia?
- BEAR
    - Loro fanno le query sulle versioni numerate, noi sul tempo.
        - Dobbiamo bloccare il tempo per ogni versione, in maniera tale da associare il tempo a una specifica versione
    - Diff query
        - Noi facciamo la query su una versione e diciamo in che modo le entità che rispondono alla query sono cambiate in quel delta
        - Loro forniscono i diversi risultati per la query tra le versioni 1 e n
    - Version query
        - È praticamente una cross-version
        - Loro forniscono i risultati annotati con le versioni in cui quei risultati ci sono