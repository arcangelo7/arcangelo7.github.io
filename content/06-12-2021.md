---
{"publish":true,"created":"2025-10-15T16:14:46.541+02:00","modified":"2021-12-06T12:00:00.000+01:00","cssclasses":""}
---


## Cosa ho fatto

- Ho studiato tutta la tesi di Fabio Mariani.
- Ho studiato tutti gli script della repository meta:
    - run_preprocess.py
    - run_process.py
    - scripts
        - curator.py
        - creator.py
    - lib
        - finder.py
        - csvmanager.py
        - id_manager
            - issnmanager.py
            - isbnmanager.y
            - orcid_manager.py
            - doimanager.py
            - identifiermanager.pyy
    - crossref
        - crossrefProcessing.py
    - orcid
        - index_orcid_doi.py
- Ho raggruppato codice ripetuto in funzioni e rimosso alcune ripetizioni. Tutti i test sono stati eseguiti per verificare che non ci fossero bug e nuovi test sono stati aggiunti. Non riporto qui tutte le modifiche, perch√© si trovano nella pull request che ho preparato: https://github.com/opencitations/meta/pull/9
- Ho riflettuto su come salvare i csv restituiti in output dal Creator. Ecco un'idea:
    - I dati vengono salvati in file csv di n righe, dove n √® un numero arbitrario. Ogni file ha nome meta_[m].csv, dove m √® un intero sequenziale, ad esempio meta_3.csv.
    - Obiezione: come trovare rapidamente informazioni al loro interno?
        - Soluzione: si utilizza un **indice analico**, dei file json in cui le chiavi sono i nomi delle entit√† e i valori sono set contenenti i nomi dei file in cui quelle entit√† sono contenute. Volendo, i nomi possono essere abbreviati in un set di interi.
    - Obiezione: questa soluzione non √® scalabile! Il file potrebbe raggiungere dimensioni astronomiche.
        - Soluzione: gli indici vengono distribuiti in varie cartelle, una per ogni tipologia di entit√†. Ci saranno quindi le cartella ar, br, ra, re e meta. Ciascuna cartella contiene solo indici relativi a quel tipo di entit√†. Ogni indice al suo interno contiene k entit√†, dove k √® un numero intero arbitrario. I nomi dei file degli indici sono parlanti. Un indice ha nome [start_end].json, ad esempio 1_1000.json √® un indice che contiene le entit√† dalla 1 alla 1000. L'informazione sul tipo √® nel nome della cartella e non viene ripetuta nel nome del file.
    - Vantaggi:
        - Gli indici permettono di trovare al volo i file csv desiderati a partire dall'URI delle entit√†.
        - Gli indici possono essere generati a posteriori.
        - Gli indici si possono aggiornare facilmente. √à possibile aggiungere, rimuovere e modificare le informazioni al loro interno.
        - Gli indici prescindono da come sono fatti i file csv. In particolare, prescindono dalle loro  dimensioni e dal contenuto.
        - √à una soluzione scalabile.
    - Svantaggi:
        - Vengono generati dei file in pi√π, l'informazione sulla posizione delle entit√† non √® intrinseca nella nomenclatura dei file csv.
        - Bisogna scrivere il codice per generare e aggiornare gli indici.
        - Non conosco l'intero codice di OpenCitations, ma magari questo sistema entra in conflitto con un'altra parte del workflow.
        - Forse non √® quello che gli utenti vogliono.
- Ho cominciato a studiare **software design pattern**, partendo dai [SOLID principles](http://staff.cs.utu.fi/staff/jouni.smed/doos_06/material/DesignPrinciplesAndPatterns.pdf) di Robert C. Martin (che per ragioni che mi sfuggono viene chiamato Uncle Bob).

## Domande

<aside>
üí° Per tutti i punti seguenti, √® implicito che i miei suggerimenti sono stati testati. Laddove i test non esistevano, sono stati aggiunti.

</aside>

- La funzione [**clean_id_list](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/scripts/curator.py#L421)** ha due bug:
    1. Modifica la lista id_list mentre cicla su di essa. Questo causa un index error, che viene gestito tramite eccezione invece di essere risolto a monte.
    2. Non funziona se il prefisso META √® scritto in maiuscolo (if "meta" in elem).
    
    Riporto le modifiche che propongo a margine del codice originale.
    
    Inoltre ho due domande: 
    
    1. Sono previsti identificatori case-sensitive? Se no, si potrebbe mettere in minuscolo tutto quanto all'inizio anzich√© pi√π volte com'√® adesso.
    2. Perch√© se c'√® pi√π di un MetaID tutti i MetaIDs vengono rimossi dalla lista id_list? (if len(how_many_meta) > 1: )
    
    ```python
    def clean_id_list(id_list, br=True):
    		if br:
    		    pattern = "br/"
    		else:
    		    pattern = "ra/"
    		metaid = ""
    		id_list = list(filter(None, id_list))
    		how_many_meta = [i for i in id_list if i.lower().startswith('meta')]
    		if len(how_many_meta) > 1:
    		    for pos, elem in enumerate(id_list): # enumerate(list(id_list))
    		        if "meta" in elem: # elem.lower()
    		            id_list[pos] = "" # Perch√©?
    		else:
    		    for pos, elem in enumerate(id_list): # enumerate(list(id_list))
    		        try: # non serve
    		            elem = Curator.string_fix(elem)
    		            identifier = elem.split(":", 1)
    		            value = identifier[1]
    		            schema = identifier[0].lower()
    		            if schema == "meta":
    		                if "meta:" + pattern in elem:
    		                    metaid = value.replace(pattern, "")
    		                else: # Non serve
    		                    id_list[pos] = ""
    										# id_list[pos] = "" Basta questo, tanto l'id viene comunque eliminato da id_list in caso contenga lo schema meta:
    		            else:
    		                newid = schema + ":" + value
    		                id_list[pos] = newid
    		        except IndexError: # Non serve
    		            id_list[pos] = "" # Non serve
    		if metaid: # Non serve, √® una ripetizione di id_list[pos] = "". Inoltre, √® fragile perch√© non √® detto che meta sia stato scritto in minuscolo.
    		    id_list.remove("meta:" + pattern + metaid)
    		id_list = list(filter(None, id_list))
    		return id_list, metaid
    ```
    
- La funzione [**clean_title**](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/scripts/curator.py#L652) ha un problema: se un titolo √® tutto maiuscolo ma contiene acronimi, gli acronimi vengono erroneamente trasformati in minuscolo. √à una scelta voluta?
    
    In ogni caso, si potrebbe utilizzare un set di acronimi da controllare prima di eseguire title.lower(). Questo ulteriore passaggio non impatterebbe sull'efficienza della funzione, perch√© la ricerca in un set ha complessit√† O(1).
    
    ```python
    def clean_title(title:str):
    		title = title.replace("\0", "")
    		if title.isupper():
    				title = title.lower()
    				# Mia proposta
    				# if not any(w in acronyms_set for w in title):
    		      # title = title.lower()
    		words = title.split()
    		for pos, w in enumerate(words):
    		    if any(x.isupper() for x in w):
    		        pass
    		    else:
    		        words[pos] = w.title()
    		newtitle = " ".join(words)
    		return newtitle
    ```
    
- Vorrei dedicare qualche minuto a riguardare insieme l'implementazione dell'albero decisionale (funzione [id_worker](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/scripts/curator.py#L826)). Ho l'impressione che l'implementazione non copra tutti i casi previsti dall'albero, ma potrei sbagliarmi.
- L'implementazione volta a normalizzare il formato delle date √® interessante. Ho capito come funziona [parse_hack](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/scripts/curator.py#L1127), ma non ho capito quale problema risolva [l'euristica successiva](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/scripts/curator.py#L100) che tenta di tagliare la stringa della data nel caso questa sia lunga 10 o 7 caratteri.
    
    ```python
    try:
        date = self.parse_hack(date)
    except ValueError:
        try:
            if len(date) == 10:
                try:
                    newdate = date[:-3]
                    date = self.parse_hack(newdate)
                except ValueError:
                    try:
                        newdate = date[:-6]
                        date = self.parse_hack(newdate)
                    except ValueError:
                        date = ""
            elif len(date) == 7:
                try:
                    newdate = date[:-3]
                    date = self.parse_hack(newdate)
                except ValueError:
                    date = ""
            else:
                date = ""
        except ValueError:
            date = ""
    
    row['pub_date'] = date
    
    @staticmethod
    # hack dateutil automatic-today-date
    def parse_hack(date):
        dt = parse(date, default=datetime(2001, 1, 1))
        dt2 = parse(date, default=datetime(2002, 2, 2))
    
        if dt.year == dt2.year and dt.month == dt2.month and dt.day == dt2.day:
            clean_date = parse(date).strftime("%Y-%m-%d")
        elif dt.year == dt2.year and dt.month == dt2.month:
            clean_date = parse(date).strftime("%Y-%m")
        elif dt.year == dt2.year:
            clean_date = parse(date).strftime("%Y")
        else:
            clean_date = ""
        return clean_date
    ```
    
- Non capisco cosa controllino le varie funzioni __checkdigit(), ad esempio quella in [issnmanager.py](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/lib/id_manager/issnmanager.py#L39)
    
    ```python
    @staticmethod
    def __check_digit(issn):
        result_partial_sum = 0
        for i, n in zip(range(8, 1, -1), issn[:4] + issn[5:8]):
            result_partial_sum += i * int(n)
        reminder = result_partial_sum % 11
        reminder_sub = 11 - reminder
        correct_check_digit = \
            str(reminder_sub) == issn[8] or \
            (reminder == 0 and issn[8] == "0") or \
            (reminder_sub == 10 and issn[8] == "X")
    
        result_full_sum = 0
        for i, n in zip(range(8, 0, -1), issn[:4] + issn[5:]):
            result_full_sum += i * (10 if n == "X" else int(n))
        confirm_check_digit = result_full_sum % 11 == 0
    
        return correct_check_digit and confirm_check_digit
    ```
    
- In crossrefProcessing.py, come mai [orcid_finder](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/crossref/crossrefProcessing.py#L190) viene usato per gli autori e non per gli editor?
- Nella sua tesi, Fabio dice che √® possibile filtrare il dizionario risultante in output da [csv_creator()](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/crossref/crossrefProcessing.py#L21) in crossrefProcessing, al fine di conservare solo le entit√† il cui DOI √® presente su COCI (pagina 88). Tuttavia, non trovo il codice per farlo.
- ORCID √® in ritardo sul rilascio del dump del 2021, che doveva uscire a Ottobre. Dovr√≤ generare nuovamente l'indice doi-orcid quando sar√† uscito?
- Non ho trovato documenti riguardati il caso d'uso di OpenCitations Meta, che se ricordo bene ha riguardato Wikidata. Dove li trovo?

## Domande per Fabio

- [**clean_id_list](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/scripts/curator.py#L421):**
    - Modifica la lista id_list mentre cicla su di essa. Questo causa un index error, che viene gestito tramite eccezione invece di essere risolto a monte.
    - Non funziona se il prefisso META √® scritto in maiuscolo (if "meta" in elem).
    - Perch√© se c'√® pi√π di un MetaID tutti i MetaIDs vengono rimossi dalla lista id_list? (if len(how_many_meta) > 1: )
        - Creare un test con due metaid uguali e diversi
- Vorrei dedicare qualche minuto a riguardare insieme l'implementazione dell'albero decisionale (funzione [id_worker](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/scripts/curator.py#L826)). Ho l'impressione che l'implementazione non copra tutti i casi previsti dall'albero, ma potrei sbagliarmi.
    - Nel commento della riga 849 si legge che se c'√® un id meta non ci si preoccupa di possibili conflitti. Leggendo l'albero per√≤, √® possibile arrivare a dei conflitti anche in presenza di un'id meta.
    - In effetti, dal codice non capisco dove venga gestito il caso 3, perch√© non trovo il caso meta id + altri id gi√† esistenti.
    - [Riga 962](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/scripts/curator.py#L955) e [riga 996](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/scripts/curator.py#L996): che casi sono?
- A cosa serve il campo others nei dizionari delle entit√†? A contenere i wannabeid? √à dove avviene il merge tra due linee che sono la stessa linea. Gli altri wannabe con cui √® presente quell'entit√†.
- Nella funzione [conflict](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/scripts/curator.py#L467), non dovrebbe essere retrieve_id(ids[1], ids[0])? I test non passano se li inverto.
- [Riga 66](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/scripts/curator.py#L66): perch√© -= 1? Controllare testcase_13/test1

## Appunti incontro

- Problema indici: grande mole di modifiche. Usiamo sempre json-ld. Produciamo csv solo alla fine.
- Guardare https://github.com/opencitations/WCW. Cercare convertitore in json
- [crossrefProcessing.py](http://crossrefProcessing.py) output tanti CSV quanti sono i file di Crossref
- Esplorare set acronimi
- __check_digit √® calcolato sulle cifre che lo precedono.
- Fare orcid_finder anche per gli editor
- Usare normalizer anche in Curator.py
- Aggiungere flag per validazione tramite API