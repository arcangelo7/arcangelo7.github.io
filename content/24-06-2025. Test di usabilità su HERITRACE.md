---
{"publish":true,"created":"2025-10-15T16:14:46.560+02:00","modified":"2025-06-24T12:00:00.000+02:00","cssclasses":""}
---


# La Novitade

## Meta

- Rilanciato dump di Meta
- Rilanciato produzione dei CSV a partire dal triplestore
- Rilanciato caricamento novità provenance
- create_archive.sh e extract_archive.sh. Creano archivi compressi splittando in file di n dimensioni, tipo oc_meta_prov_06_06.tar.gz.part000 oc_meta_prov_06_06.tar.gz.part001 ecc, dove la dimensione è personalizzabile. extract_archive.sh verrà fornito insieme ai dati per consentire l'estrazione
	```shell
	Usage: ./create_archive.sh SOURCE_DIR OUTPUT_DIR ARCHIVE_NAME MAX_SIZE
	
	Parameters:
	  SOURCE_DIR    Path to the directory to archive
	  OUTPUT_DIR    Directory where to create the archive parts
	  ARCHIVE_NAME  Base name for the archive files
	  MAX_SIZE      Maximum size per file (e.g., 10G, 500M, 2T)
	
	Example:
	  ./create_archive.sh /mnt/arcangelo/repositories/virtuoso_utilities/virtuoso-data ./backups oc_meta_prov_06_06 10G
	
	Options:
	  --help        Show this help
	
	```
	```shell
	Usage: ./extract_archive.sh PART_FILE [EXTRACT_TO]
	
	Parameters:
	  PART_FILE     Path to any .part file (e.g., archive.tar.gz.part000)
	  EXTRACT_TO    Directory to extract to (optional, default: current dir)
	
	Example:
	  ./extract_archive.sh ./backups/oc_meta_prov_06_06.tar.gz.part000 ./restored
	
	Special options (replace EXTRACT_TO):
	  --list-only   Only list contents without extracting
	  --recreate    Only recreate complete archive without extracting
	  --help        Show this help
	```

## RML

- Spostato il codice dal repo di Tijs a uno mio più verticale sulla questione SQL per pulizia del repo e mantenibilità
	- Mancava un sistemna di pull automatico delle immagini di Postgres e GraphDB da Docker Hub. Lo aggiunto per rendere più lineare e riproducibile il sistema
- Scritto a Mario Scrocca su Linkedin
- KROWN
	- Vari tipi di benchmark: ho scelto il generatore di Mappings
		- Variabili:
			- Numeri triples maps (3, 5, 8)
			- Numero di predicate object maps (2, 3, 5)
			- Numero di membri, ovvero quante entità vengono create nel knowledge graph (1000, 10000, 50000)
			- Numero di proprietà, ovvero quante proprietà per ogni entità (5, 8, 12)
			- Value size, ovvero quanto sono lunghi i valori delle proprietà (50, 100, 150)
			- rdb_host,  rdb_port, rdb_username, rdb_password, rdb_type per il caricamento automatico dei dati sul database
	- Gli altri benchmark sono
		- RAW: produce CSV e tabelle (numero di righe, colonne e celle). A me non va bene perché mi servono i mapping
		- Duplicati: produce dati con duplicati, sia i dati grezzi che i mapping. Testa la gestione della qualità dei dati. Boh, forse serve, non saprei
		- Joins: testa scenari complessi di join tra tabelle Devo capire se lo sto supportando o no.
	- Ho scritto un programma che tira su un container PostreSQL per il benchmark, crea i file di configurazione per i 3 benchmark su descritti, e il esegue, salvando i risultati.

## Umanistica Digitale

- L'editor o chi per lui ha modificato lo stile citazionale dell'articolo per HERITRACE da APA a IEEE, ma ha lasciato i riferimenti in ordine alfabetico nella bibliografia, quindi i numeri nel testo sono disordinati. Io trovo questa cosa estremamente irritante, ma ho verificato che è stata fatta in maniera sistematica in molti altri articoli di Umanistica Digitale.
- Inoltre nell'articolo sono saltati tutti i riferimenti interni a numeri di sezione, perché la rivista non numera le sezioni!

## HERITRACE

- Scaletta: https://docs.google.com/document/d/1M8MXjmT9Fv8IjCgGSVrOA8pI4fs2yksdCko5YWmFk8Q/edit?usp=sharing
- User testing: https://github.com/opencitations/heritrace/tree/main/user_testing