---
title: "2021-12-22"
editUrl: false
---

## Cosa ho fatto

<aside>
✅ Questo simbolo indica che mi sono limitato ad aggiungere dei test e scrivere la documentazione, poiché non ho trovato bug.

</aside>

* Nuovo script [cleaner.py](https://github.com/opencitations/meta/blob/master/scripts/cleaner.py), contenente la classe Cleaner, che si inizializza passando una stringa, dalla quale vengono immediatamente rimossi i caratteri nulli (’\0’). I metodi di Cleaner corrispondono a tutte le funzioni relative alla pulizia di stringhe. Tutte i metodi contenuti sono stati **documentati** in [reStructuredText](https://docutils.sourceforge.io/rst.html) e **testati** con **dati reali**. Ecco l’elenco dei metodi contenuti:
  * string\_fix, che si occupa di sostituire hyphen-minus a tutti gli altri tipi di hyphen, dash e segno meno.
    * Corretto un bug per cui veniva ritornata la stringa originale senza apportare sostituzione alcuna.
    * Ora la sostituzione non avviene tramite il glifo, ma tramite l’encoding utf8. Avevo paura che usando il glifo un copia-incolla erroneo introducesse un errore invisibile.
    * La funzione è stata ribattezzata normalize\_hyphens, un nome più esplicito.
  * clean\_title ✅
  * clean\_date ✅
  * clean\_name ✅
* Ho testato e documentato i metodi della classe [ResourceFinder](https://github.com/opencitations/meta/blob/master/lib/finder.py).
  * retrieve\_venue\_from\_meta.
    * Questo metodo funzionava in maniera ricorsiva. Per ogni venue cercava i volumi corrispondenti e per ogni volume cercava gli issue corrispondenti, ma c’erano due bug:
      * Mancava la chiave ‘id’ in riferimento al dizionario sugli issue.
      * C’era un **bug nella ricorsione**, \*\*\*\*che si manifestava in presenza di più issue associati allo stesso volume. Evidenzio entrambi i bug nel codice:

        ```python
        def retrieve_vvi(self, meta, content):
                query = """
                        SELECT DISTINCT ?res 
                            (group_concat(DISTINCT  ?type;separator=' ;and; ') as ?type_)
                            (group_concat(DISTINCT  ?title;separator=' ;and; ') as ?title_)

                        WHERE {
                            ?res <%s> <%s>.
                            ?res a ?type.
                            ?res <%s> ?title.
                        } group by ?res

                        """ % (GraphEntity.iri_part_of, "https://w3id.org/oc/meta/br/" + str(meta),
                               GraphEntity.iri_has_sequence_identifier)
                result = self.__query(query)
                if result["results"]["bindings"]:
                    results = result["results"]["bindings"]
                    for x in results:
                        res = str(x["res"]["value"]).replace("https://w3id.org/oc/meta/br/", "")
                        title = str(x["title_"]["value"])
                        types = str(x["type_"]["value"]).split(" ;and; ")
                        if content:
                            if str(GraphEntity.iri_journal_issue) in types:
        												# Qui dovrebbe essere content["issue"][title]['id'] = res
                                content["issue"][title] = res
                            elif str(GraphEntity.iri_journal_volume) in types:
                                content["volume"][title] = dict()
                                content["volume"][title]["id"] = res
                                content["volume"][title]["issue"] = dict()
        												# Qui parte la ricorsione
                                content["volume"][title]["issue"] = self.retrieve_vvi(res, None)
        								# Problema: se c'è più di un x 
        								# content smette di essere None anche se ci trova nella ricorsione,
        								# sollevando un'eccezione di tipo KeyError
                        else:
                            if str(GraphEntity.iri_journal_issue) in types:
                                content = dict()
                                content[title] = dict()
                                content[title]['id'] = res
                return content
        ```

        Ho fixato il bug eliminando la ricorsione ed effettuando una singola ricerca SPARQL che tramite frbr:partOf+ trova direttamente tutti i volumi e gli issue. Ecco la nuova funzione:\`\`\`

        ```python
        ```

{% raw %}
def **retrieve\_vvi(self, meta:str, content:Dict\[str, dict]) -> dict:
query = f'''
SELECT DISTINCT ?res
(GROUP\_CONCAT(DISTINCT ?container; separator=' ;and; ') AS ?container*)
(GROUP\_CONCAT(DISTINCT ?type; separator=' ;and; ') AS ?type*)
(GROUP\_CONCAT(DISTINCT ?title) AS ?title\_)
WHERE {{
?res <{GraphEntity.iri\_part\_of}>+ [https://w3id.org/oc/meta/br/{meta}](https://w3id.org/oc/meta/br/{meta});
<{GraphEntity.iri\_part\_of}> ?container;
a ?type;
<{GraphEntity.iri\_has\_sequence\_identifier}> ?title.
}} group by ?res
'''
result = self.**query(query)
if result\['results']\['bindings']:
results = result\['results']\['bindings']
for x in results:
res = str(x\['res']\['value']).replace('[https://w3id.org/oc/meta/br/](https://w3id.org/oc/meta/br/)', '')
container = str(x\['container*']\['value'])
title = str(x\['title*']\['value'])
types = str(x\['type\_']\['value']).split(' ;and; ')
if str(GraphEntity.iri\_journal\_issue) in types and self.\_\_is\_contained\_in\_venue(results, container):
content\['issue'].setdefault(title, dict())
content\['issue']\[title]\['id'] = res
elif str(GraphEntity.iri\_journal\_volume) in types:
content\['volume'].setdefault(title, dict())
content\['volume']\[title]\['id'] = res
content\['volume']\[title]\['issue'] = self.\_\_retrieve\_issues\_by\_volume(results, res)
return content
{% endraw %}
\`\`\`
\- retrieve\_br\_from\_id ✅
\- retrieve\_metaid\_from\_id ✅
\- retrieve\_ra\_from\_meta ✅
\- retrieve\_ra\_from\_id ✅
\- retrieve\_ra\_sequence\_from\_meta ✅
\- retrieve\_re\_from\_br\_meta ✅
\- retrieve\_br\_info\_from\_meta ✅
\- \_\_type\_it ✅
\- \_\_vvi\_find ✅

* Ho cominciato a testare i metodi di Curator
  * clean\_id\_list ✅
* Ho aggiunto un plugin che permette di ottenere l’elenco di tutti i DOI contenuti in COCI a partire dal dump. La documentazione del [README](https://github.com/opencitations/meta/blob/master/README.md) è stata aggiornata per spiegare come usare questo plugin.

## Domande

* Nella tesi di Fabio a pagina 70 si dice che tutti i tipi di hyphen, dash e il segno meno devono essere sostituiti da un soft-hyphen ([U+00AD](https://en.wikipedia.org/wiki/Soft_hyphen)). Tuttavia, alle pagine 29-30 si dice che le date e i numeri delle pagine devono essere separati da un hyphen-minus ([U+002D](https://en.wikipedia.org/wiki/Hyphen-minus)). Immagino che la seconda sia quella giusta, visto che il soft hyphen serve per la sillabazione, giusto?

* Ho notato che Meta necessita di un **file di configurazione** per funzionare, oltre agli **argomenti** specificati quando si lancia l’applicazione da terminale. Personalmente, trovo questa soluzione un po’ scomoda e ridondante. Direi, o l’una o l’altra: proporrei di spostare tutta la configurazione in un unico file YAML. Dopodiché, l’applicazione si lancia specificando unicamente il percorso di questo file. Cosa ne pensi?
  * Preferirei un file di configurazione agli argomenti perché i parametri sono tanti. Così vanno scritti una volta sola ed è più facile modificarli su file che da terminale, riducendo la possibilità di commettere errori.
  * Ho pensato a **YAML** perché è molto piacevole da leggere e, a differenza di JSON, è commentabile.

* In riferimento al campo ‘id’ del CSV, la tesi dice:

  > The cell contains the IDs for the document described within the line.

  Mi confermi che tali ID devono essere solo quelli del documento descritto? Quindi niente id degli agenti responsabili, editori, riviste ecc.

* La funzione retrieve\_ra\_sequence\_from\_br\_meta restituisce gli agenti responsabili di una risorsa nel giusto ordine. Essa è stata implementata per funzionare per autori, curatori e case editrici. Tuttavia, non mi è mai capitato di vedere più case editrici per una singola risorsa bibliografica. Esiste questa possibilità?
