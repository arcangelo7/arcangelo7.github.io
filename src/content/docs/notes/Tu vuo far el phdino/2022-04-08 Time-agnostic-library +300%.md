---
title: 2022-04-08 Time-agnostic-library +300%
editUrl: false
---

## Cosa ho fatto

* Ecco quali funzionalit√† di Meta sono state testate con successo su oc\_ficlit:
  * Generazione dell‚Äôinput di Meta a partire dal dump di Crossref
  * Preparazione al multiprocess
* Risolto un bug nella preparazione al multiprocess per cui venivano paradossalmente introdotte entit√† conflittuali. Il problema si risolve preprocessando le venue in single-process, poich√© possono comparire in pi√π file contemporaneamente, mentre gli autori possono essere preprocessati in multi-process.
* In precedenza venivano preprocessate tutte le venue multi-publisher con relativi volumi e issue e tutti gli autori ed editor, dopodich√© i dati venivano divisi per casa editrice in modo da poter essere elaborati da pi√π processi in sicurezza.
  * Tale sistema si √® dimostrato fallimentare dai miei test su oc\_ficlit, perch√© si vengono a creare file CSV che pesano GB, come quello relativo all‚Äô‚ÄùAmerican Physical Society‚Äù, e altri con una riga sola, come quello relativo a ‚ÄúSci-Comm Consulting Ltd‚Äù. I file pi√π massicci fanno s√¨ che in multi-process con 10 workers oc\_ficlit finisca la RAM.
  * Per risolvere questo problema, ora vengono preprocessate tutte le venue (in single-process) e tutti i publisher, che sono appena 14,367 e con 24 workers sulla mia macchina si processano in appena 2 minuti.
  * I publisher vengono precaricati sul triplestore come gli autori e gli editor, quindi come semplici agenti responsabili senza ruolo e senza risorsa bibliografica associata.
* Ho implementato un sistema di **cache** anche per il plugin che genera l‚Äôinput di Meta a partire dal dump di **Crossref**. Tale sistema √® analogo a quello di Meta e funziona sia se il dump √® compresso sia se √® decompresso.
* Ho trovato la rivista con issue ‚Äú7-8 (10)‚Äù: [10.1134/s0370274x19190081](http://doi.org/10.1134/s0370274x19190081)
* Confermo che ogni nuovo literal viene aggiunto all‚Äôindice testuale di Blazegraph

  > If enabled, then each literal added to the database (by appearing in the ‚ÄúO‚Äù position of a statement) is also added to the text index ([https://github.com/blazegraph/database/wiki/FullTextSearch](https://github.com/blazegraph/database/wiki/FullTextSearch))
* Novit√† relative a **time-agnostic-library**:
  * Ora tutti i test che coinvolgono query vengono eseguiti sia su Blazegraph che su GraphDB, per garantire la piena compatibilit√† con questi due triplestore.
    * Tutti i test sono stati superati.

  * Ho caricato i dataset di test su Zenodo. Lanciando `poetry run tests` tutto l‚Äôoccorrente, se non √® gi√† presente, viene automaticamente scaricato ed estratto nella cartella corretta. Dopodich√©, sia Blazegraph che GraphDB vengono lanciati in automatico, in modo da consentire l‚Äôesecuzione dei test.

  * Risolto l‚Äôannoso problema menzionato nel seguente blocco: [Tu vuo far el phdino/22-03-2022 GraphDB vs Blazegraph](/notes/tu-vuo-far-el-phdino/22-03-2022-graphdb-vs-blazegraph)
    * Non √® un problema legato ai limiti sul multi-threading imposti dalla versione gratuita. Ho testato la versione a pagamento tramite prova di 60 giorni e il problema persiste.
    * Il problema √® che ho passato come indirizzo locale dell‚Äôendpoint http\://**localhost**:7200/repositories/data anzich√© http\://**127.0.0.1**/repositories/data. In questo modo, il DNS doveva risolvere ogni volta l‚Äôindirizzo, causando una pausa di circa 1 secondo tra una query e l‚Äôaltra.

  * Ho aumentato del 330% circa le performance del processo di ricostruzione della storia delle entit√† rilevanti trovate nelle query di update. Una volta individuati i loro URI, tali entit√† vengono ricostruite in multithreading. Per ricostruire 2814 entit√† si impiegano adesso circa 45 secondi anzich√© 2 minuti e mezzo.

      <aside>
      üëâ √à vero che sia Blazegraph che GraphDB lavorano automaticamente in multithreading, ma Python no. L‚Äôesecuzione del codice si blocca per aspettare la risposta di una query prima di lanciare la successiva. Pertanto, implementare il multithreading su operazioni di I/O porta un enorme beneficio.

      </aside>

    * Lo stesso discorso vale anche per le query sui delta: le entit√† che sono state modificate vengono identificate in multi-threading.

      <aside>
      üëâ Sono consapevole pyparsing non √® thread-safe e che viene utilizzato da rdflib per parsare le query SPARQL. Ho aggirato il problema facendo s√¨ che il parsing avvenga single-thread tramite lock. Tale parser serve solo per eseguire le query su file locali e per processare l‚Äôoutput di query gi√† avvenute, poco male.

      </aside>

    [https://github.com/RDFLib/rdflib/issues/1282](https://github.com/RDFLib/rdflib/issues/1282)

    [benchmarks\_before\_after\_multi\_threading.xlsx](08-04-2022%20Time-agnostic-library%20+300%25%207ac33a7161ba4cdfa13ff8d639cdec4c/benchmarks_before_after_multi_threading.xlsx)

  * Ho dovuto modificare il parametro di configurazione relativo alla cache, per consentire la distinzione tra endpoint di lettura e scrittura. Infatti, GraphDB ha due endpoint separati per le due operazioni.

  * Ho aggiornato README e documentazione per spiegare le novit√† relative al file di configurazione e al supporto a GraphDB.

  * Ho rilasciato la versione **3.0.0** (non √® retrocompatibile per via del supporto a rdflib 6.1.1.).

  * Novit√† relative ai benchmark:
    * Ho ampliato l‚Äôautomatismo della procedura di benchmark in modo che i benchmark vengano eseguiti con pi√π triplestore. Basta sempre lanciare un file bash, dopodich√© i benchmark vengano lanciati prima su Blazegraph e poi su GraphDB, coi i relativi file di configurazione e metodi per lanciare e chiudere i database pre-impostati.

## Domande

* Esiste un modo per ricavare il nome del triplestore dall‚ÄôURL dell‚Äôendpoint? Per fare l‚Äôesempio di Blazegraph, nei metadati di una risposta HTTP si legge semplicemente che il server √® ‚ÄòJetty(9.4.z-SNAPSHOT)‚Äô, ovvero un generico server basato su Java, che viene usato anche da altri triplestore.
* Nel file di configurazione YAML gli indici testuali sono di mutua esclusione e se ne pu√≤ specificare al massimo uno. Tuttavia, non c‚Äô√® niente nel formato YAML che forzi questo comportamento, che io sappia. Qualche idea su come evitare che l‚Äôutente sbagli e specifichi pi√π di un indice?
* Il processo master conta come processo? In altre parole, se l‚Äôutente specifica 24 nel parametro max\_workers del file di configurazione di Meta si aspetta che vengano processati 24 CSV contemporaneamente o che ci siano al massimo 24 processi? Perch√© nel secondo caso i file processati contemporaneamente saranno 23, a cui si aggiunge il processo master che coordina gli altri. Il problema della seconda opzione √® che, se l‚Äôutente indica 2 nel parametro max\_workers, i file di input vengono paradossalmente processati in single-process. Cosa ne pensate?
