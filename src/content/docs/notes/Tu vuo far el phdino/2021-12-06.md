---
title: "2021-12-06"
editUrl: false
---

## Cosa ho fatto

* Ho studiato tutta la tesi di Fabio Mariani.
* Ho studiato tutti gli script della repository meta:
  * run\_preprocess.py
  * run\_process.py
  * scripts
    * curator.py
    * creator.py
  * lib
    * finder.py
    * csvmanager.py
    * id\_manager
      * issnmanager.py
      * isbnmanager.y
      * orcid\_manager.py
      * doimanager.py
      * identifiermanager.pyy
  * crossref
    * crossrefProcessing.py
  * orcid
    * index\_orcid\_doi.py
* Ho raggruppato codice ripetuto in funzioni e rimosso alcune ripetizioni. Tutti i test sono stati eseguiti per verificare che non ci fossero bug e nuovi test sono stati aggiunti. Non riporto qui tutte le modifiche, perch√© si trovano nella pull request che ho preparato: [https://github.com/opencitations/meta/pull/9](https://github.com/opencitations/meta/pull/9)
* Ho riflettuto su come salvare i csv restituiti in output dal Creator. Ecco un'idea:
  * I dati vengono salvati in file csv di n righe, dove n √® un numero arbitrario. Ogni file ha nome meta\_\[m].csv, dove m √® un intero sequenziale, ad esempio meta\_3.csv.
  * Obiezione: come trovare rapidamente informazioni al loro interno?
    * Soluzione: si utilizza un **indice analico**, dei file json in cui le chiavi sono i nomi delle entit√† e i valori sono set contenenti i nomi dei file in cui quelle entit√† sono contenute. Volendo, i nomi possono essere abbreviati in un set di interi.
  * Obiezione: questa soluzione non √® scalabile! Il file potrebbe raggiungere dimensioni astronomiche.
    * Soluzione: gli indici vengono distribuiti in varie cartelle, una per ogni tipologia di entit√†. Ci saranno quindi le cartella ar, br, ra, re e meta. Ciascuna cartella contiene solo indici relativi a quel tipo di entit√†. Ogni indice al suo interno contiene k entit√†, dove k √® un numero intero arbitrario. I nomi dei file degli indici sono parlanti. Un indice ha nome \[start\_end].json, ad esempio 1\_1000.json √® un indice che contiene le entit√† dalla 1 alla 1000. L'informazione sul tipo √® nel nome della cartella e non viene ripetuta nel nome del file.
  * Vantaggi:
    * Gli indici permettono di trovare al volo i file csv desiderati a partire dall'URI delle entit√†.
    * Gli indici possono essere generati a posteriori.
    * Gli indici si possono aggiornare facilmente. √à possibile aggiungere, rimuovere e modificare le informazioni al loro interno.
    * Gli indici prescindono da come sono fatti i file csv. In particolare, prescindono dalle loro  dimensioni e dal contenuto.
    * √à una soluzione scalabile.
  * Svantaggi:
    * Vengono generati dei file in pi√π, l'informazione sulla posizione delle entit√† non √® intrinseca nella nomenclatura dei file csv.
    * Bisogna scrivere il codice per generare e aggiornare gli indici.
    * Non conosco l'intero codice di OpenCitations, ma magari questo sistema entra in conflitto con un'altra parte del workflow.
    * Forse non √® quello che gli utenti vogliono.
* Ho cominciato a studiare **software design pattern**, partendo dai [SOLID principles](http://staff.cs.utu.fi/staff/jouni.smed/doos_06/material/DesignPrinciplesAndPatterns.pdf) di Robert C. Martin (che per ragioni che mi sfuggono viene chiamato Uncle Bob).

## Domande

<aside>
üí° Per tutti i punti seguenti, √® implicito che i miei suggerimenti sono stati testati. Laddove i test non esistevano, sono stati aggiunti.

</aside>

* La funzione [\*\*clean\_id\_list](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/scripts/curator.py#L421)\*\* ha due bug:

  1. Modifica la lista id\_list mentre cicla su di essa. Questo causa un index error, che viene gestito tramite eccezione invece di essere risolto a monte.
  2. Non funziona se il prefisso META √® scritto in maiuscolo (if "meta" in elem).

  Riporto le modifiche che propongo a margine del codice originale.

  Inoltre ho due domande:

  1. Sono previsti identificatori case-sensitive? Se no, si potrebbe mettere in minuscolo tutto quanto all'inizio anzich√© pi√π volte com'√® adesso.
  2. Perch√© se c'√® pi√π di un MetaID tutti i MetaIDs vengono rimossi dalla lista id\_list? (if len(how\_many\_meta) > 1: )

  ```python
  def clean_id_list(id_list, br=True):
  		if br:
  		    pattern = "br/"
  		else:
  		    pattern = "ra/"
  		metaid = ""
  		id_list = list(filter(None, id_list))
  		how_many_meta = [i for i in id_list if i.lower().startswith('meta')]
  		if len(how_many_meta) > 1:
  		    for pos, elem in enumerate(id_list): # enumerate(list(id_list))
  		        if "meta" in elem: # elem.lower()
  		            id_list[pos] = "" # Perch√©?
  		else:
  		    for pos, elem in enumerate(id_list): # enumerate(list(id_list))
  		        try: # non serve
  		            elem = Curator.string_fix(elem)
  		            identifier = elem.split(":", 1)
  		            value = identifier[1]
  		            schema = identifier[0].lower()
  		            if schema == "meta":
  		                if "meta:" + pattern in elem:
  		                    metaid = value.replace(pattern, "")
  		                else: # Non serve
  		                    id_list[pos] = ""
  										# id_list[pos] = "" Basta questo, tanto l'id viene comunque eliminato da id_list in caso contenga lo schema meta:
  		            else:
  		                newid = schema + ":" + value
  		                id_list[pos] = newid
  		        except IndexError: # Non serve
  		            id_list[pos] = "" # Non serve
  		if metaid: # Non serve, √® una ripetizione di id_list[pos] = "". Inoltre, √® fragile perch√© non √® detto che meta sia stato scritto in minuscolo.
  		    id_list.remove("meta:" + pattern + metaid)
  		id_list = list(filter(None, id_list))
  		return id_list, metaid
  ```

* La funzione [**clean\_title**](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/scripts/curator.py#L652) ha un problema: se un titolo √® tutto maiuscolo ma contiene acronimi, gli acronimi vengono erroneamente trasformati in minuscolo. √à una scelta voluta?

  In ogni caso, si potrebbe utilizzare un set di acronimi da controllare prima di eseguire title.lower(). Questo ulteriore passaggio non impatterebbe sull'efficienza della funzione, perch√© la ricerca in un set ha complessit√† O(1).

  ```python
  def clean_title(title:str):
  		title = title.replace("\0", "")
  		if title.isupper():
  				title = title.lower()
  				# Mia proposta
  				# if not any(w in acronyms_set for w in title):
  		      # title = title.lower()
  		words = title.split()
  		for pos, w in enumerate(words):
  		    if any(x.isupper() for x in w):
  		        pass
  		    else:
  		        words[pos] = w.title()
  		newtitle = " ".join(words)
  		return newtitle
  ```

* Vorrei dedicare qualche minuto a riguardare insieme l'implementazione dell'albero decisionale (funzione [id\_worker](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/scripts/curator.py#L826)). Ho l'impressione che l'implementazione non copra tutti i casi previsti dall'albero, ma potrei sbagliarmi.

* L'implementazione volta a normalizzare il formato delle date √® interessante. Ho capito come funziona [parse\_hack](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/scripts/curator.py#L1127), ma non ho capito quale problema risolva [l'euristica successiva](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/scripts/curator.py#L100) che tenta di tagliare la stringa della data nel caso questa sia lunga 10 o 7 caratteri.

  ```python
  try:
      date = self.parse_hack(date)
  except ValueError:
      try:
          if len(date) == 10:
              try:
                  newdate = date[:-3]
                  date = self.parse_hack(newdate)
              except ValueError:
                  try:
                      newdate = date[:-6]
                      date = self.parse_hack(newdate)
                  except ValueError:
                      date = ""
          elif len(date) == 7:
              try:
                  newdate = date[:-3]
                  date = self.parse_hack(newdate)
              except ValueError:
                  date = ""
          else:
              date = ""
      except ValueError:
          date = ""

  row['pub_date'] = date

  @staticmethod
  # hack dateutil automatic-today-date
  def parse_hack(date):
      dt = parse(date, default=datetime(2001, 1, 1))
      dt2 = parse(date, default=datetime(2002, 2, 2))

      if dt.year == dt2.year and dt.month == dt2.month and dt.day == dt2.day:
          clean_date = parse(date).strftime("%Y-%m-%d")
      elif dt.year == dt2.year and dt.month == dt2.month:
          clean_date = parse(date).strftime("%Y-%m")
      elif dt.year == dt2.year:
          clean_date = parse(date).strftime("%Y")
      else:
          clean_date = ""
      return clean_date
  ```

* Non capisco cosa controllino le varie funzioni \_\_checkdigit(), ad esempio quella in [issnmanager.py](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/lib/id_manager/issnmanager.py#L39)

  ```python
  @staticmethod
  def __check_digit(issn):
      result_partial_sum = 0
      for i, n in zip(range(8, 1, -1), issn[:4] + issn[5:8]):
          result_partial_sum += i * int(n)
      reminder = result_partial_sum % 11
      reminder_sub = 11 - reminder
      correct_check_digit = \
          str(reminder_sub) == issn[8] or \
          (reminder == 0 and issn[8] == "0") or \
          (reminder_sub == 10 and issn[8] == "X")

      result_full_sum = 0
      for i, n in zip(range(8, 0, -1), issn[:4] + issn[5:]):
          result_full_sum += i * (10 if n == "X" else int(n))
      confirm_check_digit = result_full_sum % 11 == 0

      return correct_check_digit and confirm_check_digit
  ```

* In crossrefProcessing.py, come mai [orcid\_finder](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/crossref/crossrefProcessing.py#L190) viene usato per gli autori e non per gli editor?

* Nella sua tesi, Fabio dice che √® possibile filtrare il dizionario risultante in output da [csv\_creator()](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/crossref/crossrefProcessing.py#L21) in crossrefProcessing, al fine di conservare solo le entit√† il cui DOI √® presente su COCI (pagina 88). Tuttavia, non trovo il codice per farlo.

* ORCID √® in ritardo sul rilascio del dump del 2021, che doveva uscire a Ottobre. Dovr√≤ generare nuovamente l'indice doi-orcid quando sar√† uscito?

* Non ho trovato documenti riguardati il caso d'uso di OpenCitations Meta, che se ricordo bene ha riguardato Wikidata. Dove li trovo?

## Domande per Fabio

* [\*\*clean\_id\_list](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/scripts/curator.py#L421):\*\*
  * Modifica la lista id\_list mentre cicla su di essa. Questo causa un index error, che viene gestito tramite eccezione invece di essere risolto a monte.
  * Non funziona se il prefisso META √® scritto in maiuscolo (if "meta" in elem).
  * Perch√© se c'√® pi√π di un MetaID tutti i MetaIDs vengono rimossi dalla lista id\_list? (if len(how\_many\_meta) > 1: )
    * Creare un test con due metaid uguali e diversi
* Vorrei dedicare qualche minuto a riguardare insieme l'implementazione dell'albero decisionale (funzione [id\_worker](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/scripts/curator.py#L826)). Ho l'impressione che l'implementazione non copra tutti i casi previsti dall'albero, ma potrei sbagliarmi.
  * Nel commento della riga 849 si legge che se c'√® un id meta non ci si preoccupa di possibili conflitti. Leggendo l'albero per√≤, √® possibile arrivare a dei conflitti anche in presenza di un'id meta.
  * In effetti, dal codice non capisco dove venga gestito il caso 3, perch√© non trovo il caso meta id + altri id gi√† esistenti.
  * [Riga 962](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/scripts/curator.py#L955) e [riga 996](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/scripts/curator.py#L996): che casi sono?
* A cosa serve il campo others nei dizionari delle entit√†? A contenere i wannabeid? √à dove avviene il merge tra due linee che sono la stessa linea. Gli altri wannabe con cui √® presente quell'entit√†.
* Nella funzione [conflict](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/scripts/curator.py#L467), non dovrebbe essere retrieve\_id(ids\[1], ids\[0])? I test non passano se li inverto.
* [Riga 66](https://github.com/opencitations/meta/blob/6ce6614937887261de1fefaddbcc77e31b4119d2/scripts/curator.py#L66): perch√© -= 1? Controllare testcase\_13/test1

## Appunti incontro

* Problema indici: grande mole di modifiche. Usiamo sempre json-ld. Produciamo csv solo alla fine.
* Guardare [https://github.com/opencitations/WCW](https://github.com/opencitations/WCW). Cercare convertitore in json
* [crossrefProcessing.py](http://crossrefProcessing.py) output tanti CSV quanti sono i file di Crossref
* Esplorare set acronimi
* \_\_check\_digit √® calcolato sulle cifre che lo precedono.
* Fare orcid\_finder anche per gli editor
* Usare normalizer anche in Curator.py
* Aggiungere flag per validazione tramite API
